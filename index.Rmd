---
title: "IODS-final"
author: 
- Heidi Maanonen
- heidi.maanonen@helsinki.fi
date: "26.2.2017"
output: 
  html_document:
    theme: sandstone
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_sections: true
    toc_depth: 2
    fig_caption: true
    fig_width: 6
    fig_height: 4
    code_folding: hide
---

&nbsp;

# The purpose of the final work

&nbsp;

The idea of the this final work is to show and demonstrate what I have learnt about R, data visualizing and statistics during this course called **Introduction to Open Data Science**. The course is organized by [University of Helsinki](https://wiki.helsinki.fi/display/SocStats/Introduction+to+Open+Data+Science,+spring+2017). I really want highlight that this was and is my first course and work with R programming. Considering this I like to believe that I have learnt a lot of very interesting ways of using R, RStudio and Rpackages.

In this final work we have 2 options to choose our data. First we could use one of the the datasets which we had already applied. Alternatively we could try to find a new dataset from internet in terms of our interests or just to raise the degree of difficulty, I think. And because I'm very interested in research, I wanted to find a new dataset to learn how to do the whole data wrangling and exploring process by myself. 

My intention here is to deepen my knowledge on [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) in terms of finding some latent structure of the dataset introduced in the next chapter.  

&nbsp;

# Description of the dataset

&nbsp;


I choose the dataset from [Kaggle](https://www.kaggle.com/miroslavsabo/young-people-survey), which is about **Preferencies, interests, habits, opinions and fears of young people** in Slovakia. In 2013, students of the Statistics class at [FSEV UK](https://fses.uniba.sk/en/) were asked to invite their friends to participate in this survey. Accordingly they managed to get 1 010 participants for this purpose. 

If you take a look at the Kaggle link you can see that there are huge amount of variables, that is 150 columns mainly integers but also some categorical variables. Thus for the purpose of this assignment and Principal Component Analysis I had to choose some interesting content which is funny because I choose the interests and hobbies of these young people. In addition, I also wanted to count in some demographical variables to make visualizations more versatile.

&nbsp;

## Data wrangling 

&nbsp;


You can find all of the datasets from my [GitHub Repository](https://github.com/8475394/IODS-final/tree/master/Data). The CSV-file called "raw_young_people_survey" is the original dataset from Kaggle. The "create_interests.R" is the R Script file of my data wrangling and the "interests_dem.txt" is the file what I'm going to use here.

&nbsp;

<p class="text-warning">BRIEF DESCRIPTION OF DATA WRANGLING PHASES:</p>

1. Reading the whole dataset
2. Selecting the variables of interests and hobbies including age and gender
3. Renaming some variables
4. Exploring missing values
5. Removing the rows with missing values
6. Saving the new data

&nbsp;

<p class="text-warning">SECOND PART OF DATA WRANGLING:</p>

While printing the summaries and plotting histograms I noticed that there is something "wrong" with the gender variable. This column consisted the third unnamed category containing only three participant. I assumed that these people didn't want answer to this question. But the point from data wrangling perspective was that this third category was unnamed while these were not marked as missing values. Still the Kaggle pages informed that the gender is divided to females and males. Thus, I couldn't actually know the real purpose so I made a decision to extract these particpant from the data.  You can find this part from the same R Script named as "create_interests.R". Below you can see a short description of the second part.

7. Recoding empty values as NA:s
8. Verifying that 3 of the values belong to NA:s
9. Removing the "new" rows with missing values
10. Saving the dataset again as "interests_dem.txt"


&nbsp;

## Introducing the variables 

&nbsp;

From the structure table below you see that after data wrangling part there are 878 observation and 34 variables, mostly integers, treated as continuous variables, and 1 factor variable. The first 32 variables represent different interests and hobbies of young people which were measured on the [Likert Scale](https://en.wikipedia.org/wiki/Likert_scale) from 1 to 5 (Not interested - Very interested). Last two variables contains information about age and gender, where the former varies between 15 and 30 years. The latter contains categories of female and male.

Some of these variables may need some additional information, thus I made a table for their longer and short names. However, most of the variables have same longer and shorter name. See the table after exploring the structure of the data.

&nbsp;

<p class="text-warning">DATA STRUCTURE</p>


```{r, message=FALSE, warning=FALSE}
# Reading the data with interests and demographics
interests_dem <- read.table(file.path("C:/Users/heidi/Documents/YLIOPISTO/TILASTOTIEDE/INTRODUCTION TO OPEN DATA SCIENCE/IODS-final/data", "interests_dem.txt"), header = TRUE)

# Printing the data structure
library(dplyr)
glimpse(interests_dem)
```


&nbsp;

<p class="text-warning">INTERESTS AND THEIR SHORT NAMES</p> 

&nbsp;


INTEREST        | Short name          | INTEREST    | Short name
----------------|---------------------|-------------|-------------
1. History           | History        | 18. Religion     | Religion
2. Psychology        | Psychology     | 19. Outdoor activities | Outdoor
3. Politics          | Politics       | 20. Dancing     | Dancing
4. Mathematics       | Mathematics    | 21. Playing musical instruments | Instruments
5. Physics           | Physics        | 22. Poetry writing | wPoetry
6. Internet          | Internet       | 23. Sport and leisure activities | sLeisure
7. PC Software, Hardware| PC          | 24. Sport at competitive level | sCompetitive
8. Economy, Management | Economy      | 25. Gardening | Gardening
9. Biology           | Biology        | 26. Celebrity lifestyle | Celebrities
10. Chemistry         | Chemistry     | 27. Shopping | Shopping
11. Poetry reading    | rPoetry       | 28. Science and technology | SciTec
12. Geography         | Geography     | 29. Theatre | Theatre
13. Foreign languages | Languages     | 30. Socializing with friends | Social
14. Medicine          | Medicine      | 31. Adrenaline sports | sAdrenaline
15. Law               | Law           | 32. Pets | Pets
16. Cars              | Cars          | 33. Age | Age
17. Art exhibitions   | Art           | 34. Gender | Gender


&nbsp;

## Summary tables 

&nbsp;

The dataset contains a lot of variables, also producing many summary tables. 

As you can perceive, all of the variables, besides age, varies between 1 and 5. This means that the whole scale has been used considering each of the variables. Interestingly, some distributions are quite flat, suggesting average interest toward the hobbies or interests. By this I mean that the mean and median values are around 3. These include **History, Psychology, PC, Poetry reading, Geography, Sport at competitive level, Shopping, Science and technology, Theatre and  Adrenaline sports**.  

Then there are some variables with quite low average interest, including for example **Physics, Chemistry, Poetry writing and Gardening** and very high interest, including **Internet, Languages, Outdoor activities and Socializing with friends**. 

When exploring the distributions, it is good to remember that the participants were not just the students but also their friends. This means that the participants can come from the University, working life, etc.   



```{r, fig.width=10, message=FALSE, warning=FALSE, results='asis'}
library(knitr); library(dplyr)
kable(summary(interests_dem[,1:7]), format = "pandoc", digits = 2,  caption = 'Summary 1', align = "l")

kable(summary(interests_dem[,8:14]), format = "pandoc", digits = 2,  caption = 'Summary 2', align = "l")

kable(summary(interests_dem[,15:21]), format = "pandoc", digits = 2,  caption = 'Summary 3', align = "l")

kable(summary(interests_dem[,22:28]), format = "pandoc", digits = 2,  caption = 'Summary 4', align = "l")

kable(summary(interests_dem[,29:33]), format = "pandoc", digits = 2,  caption = 'Summary 5', align = "l")


```

&nbsp;

<p class="text-warning">SUMMARY OF GENDER</p> 

This last tiny table informs us that there are 520 females and 358 males.


```{r}
Gender <- interests_dem$Gender
table(Gender)
```


&nbsp;

# Reasearch problem and initial hypotheses

&nbsp;

The research problem is to reduce the dimensions of the data by **young people's interests and hobbies** and identify and express a meaningful pattern of components in terms of clarity and exploratory fashion. First I offer some general backround information of my initial proposal and after this I present the initial hypotheses or proposal together with the colored histograms.

In this section you can see the ditributions more visually. The coloring might seem confucing at first but there is actually a strategy behind this. As I mentioned earlier, my intention is to deepen my knowledge in terms of Principal Component Analysis (PCA), hence the coloring points to **initial proposal** of the latent structure inside the data. I'm highlighting the word initial because the structure is based partially on my personal intuition and partially on the "behaviour" of the distributions. Additionally, I want to form my perception of the structure from beginning to end, rather than perform the statistical methods first and then look back and write these chapters. Thus I could call this as my learnings process.

Note that the histograms are showed regarding the original variable list while the structure is organized by proposed groups or components. Note also that gender as well as the distribution of age are visualized only for the informative purposes.


&nbsp;

## Initial proposal of latent structure and hypotheses

&nbsp;

<p class="text-warning">FIRST DIMENSION</p> 

In the beginning I maybe wouldn't have chosen the psychology here but I thought it's important that these variables share somewhat similar distributions. If these variables belong to same component, the dimension could be called something like **interest toward base disciplines of cultural characteristics with respect to human beings**.

* History
* Psychology
* Geography

&nbsp;

<p class="text-warning">SECOND DIMENSION</p>

Also this dimension contains variables with somewhat equivalent distributions and I think they share some common parts of **intellectual elements**.

* Politics      
* Economy, management
* Biology       
* Medicine
* Art exhibition

&nbsp;

<p class="text-warning">THIRD DIMENSION</p>

This dimension is a bit tricky. To me, it makes sense that the math, physics and chemistry could belong to the same scope. The variable of being interest toward law is more complicated. It could belong here or to the earlier dimension of "intellectual features". In terms of this third dimension the content of law contains a lot of details and complex attributes as well as math, physics and chemistry. Thus, if a person is interested in putting effort **to calculate details and logical problems**, this dimension can make sense (so far). 

* Mathematics
* Physics
* Chemistry
* Law

&nbsp;

Then, my intention at first was to create one more dimension for variables below until I noticed that their distribution is likely to be similar with the above variables. First I thought that religion, playing instruments, poetry writing and gardening relate to some artistic features which still could be the explanation. But according to the information of similarities in their distributions, it could be "true" that some people are interested in all of these contents. There might be a situation that **people interested in math, physics, chemistry and law would like to have some counterbalance hobbies or worldview in terms of religion**. However, it is not very easy to figure out a name representing all these variables, thus I think I need to ensure the results first. 

* Religion
* Playing musical instruments
* Poetry writing
* Gardening

&nbsp;

<p class="text-warning">FOURTH DIMENSION</p>

At this point, the fourth dimension contains the futher variables:

* Internet
* Foreign languages
* Outdoor activities
* Sport and leisure activities
* Sport at competitive level
* Socializing with friends
* Pets

There is more variablity in this dimension considering the distributions. However, I think that all these variables share the aspect of **interest toward socializing** with one way or another. 

&nbsp;

<p class="text-warning">FIFTH DIMENSION</p>

I think that this dimension contains at least PC and interest toward science and techology, since PC can be considered as technology. This can be true also in terms of cars but its ditribution doesn't fit. Finally it seems that the Andrenaline sports doesn't fit anyhere. Nevertheless, if it belongs here, the dimension could be called for example **interest toward speed and technology**.

* PC
* Science and technology
* Cars
* Adrenaline sports

&nbsp;

<p class="text-warning">SIXTH DIMENSION</p>

These variables can be close with socializing aspects regarding their actual content or meaning. However their distributions seem to somewhat different and for that reason I separated the variables below as their own dimension. It seems that within this data, these interests are more important to women than men, which could be the common nominator. Hope nobody gets hurt if I call these variables as **feminine activities**. 

* Poetry reading
* Shopping
* Theatre


&nbsp;

<p class="text-warning">SEVENTH DIMENSION</p>

This last dimension may contain the following variables:

* Dancing
* Celebrity lifestyle

I think that these share the most obvious relationship regarding their content but let's see later if the PCA agrees with me.

&nbsp;

## Histograms considering the latent structure

&nbsp;

Note that the binwidth of every histogram is set to 1 on purpose in terms to show the real amount of each level between 1 and 5. Thus I wanted to show more accurate than "more beautiful" plots. This might be one of "the curses" of the Likert scale as it kind of "wrangles" between ordinal and interval scale. 

However, I will treat these variables as continuous while recognizing the debate around this topic. Here is an interesting article by Karen Grace-Martin: [Can Likert Scale Data ever be Continuous](http://www.theanalysisfactor.com/can-likert-scale-data-ever-be-continuous/).

&nbsp;

```{r, fig.height=9, fig.width=10, message=FALSE, warning=FALSE}
library(ggplot2); library(gridExtra)

# Nice  plave to learn about ggplot: https://sesync-ci.github.io/graphics-with-ggplot2-lesson/2016/08/25/
# Palettes and colors: http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#palettes-color-brewer 

h1 <- ggplot(interests_dem, aes(interests_dem$History, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("orangered", "forestgreen")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward history") + xlab("History")

h2 <- ggplot(interests_dem, aes(interests_dem$Psychology, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("orangered", "forestgreen")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward psychology") + xlab("Psychology")

h3 <- ggplot(interests_dem, aes(interests_dem$Politics, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF6666", "#66CC99")) + theme(legend.position=c(0.9, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward politics") + xlab("Politics")

h4 <- ggplot(interests_dem, aes(interests_dem$Mathematics, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward mathematics") + xlab("Mathematics")

h5 <- ggplot(interests_dem, aes(interests_dem$Physics, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward physics") + xlab("Physics")

h6 <- ggplot(interests_dem, aes(interests_dem$Internet, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.18, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward Internet") + xlab("Internet")

h7 <- ggplot(interests_dem, aes(interests_dem$PC, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("darkorange", "#CC6600")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward PC") + xlab("PC")

h8 <- ggplot(interests_dem, aes(interests_dem$Economy, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF6666", "#66CC99")) + theme(legend.position=c(0.85, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward economy") + xlab("Economy, Management")

h9 <- ggplot(interests_dem, aes(interests_dem$Biology, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF6666", "#66CC99")) + theme(legend.position=c(0.85, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward biology") + xlab("Biology")

grid.arrange(h1, h2, h3, h4, h5, h6, h7, h8, h9, ncol = 3, nrow =3)
```

&nbsp;


```{r, fig.height=9, fig.width=10, message=FALSE, warning=FALSE}
library(ggplot2); library(gridExtra)

h10 <- ggplot(interests_dem, aes(interests_dem$Chemistry, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.85, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward chemistry") + xlab("Chemistry")

h11 <- ggplot(interests_dem, aes(interests_dem$rPoetry, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF0000", "blue")) + theme(legend.position=c(0.4, 0.9), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward rPoetry") + xlab("Poetry reading")

h12 <- ggplot(interests_dem, aes(interests_dem$Geography, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("orangered", "forestgreen")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward geography") + xlab("Geography")

h13 <- ggplot(interests_dem, aes(interests_dem$Languages, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.2, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward languages") + xlab("Foreign languages")

h14 <- ggplot(interests_dem, aes(interests_dem$Medicine, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF6666", "#66CC99")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward medicine") + xlab("Medicine")

h15 <- ggplot(interests_dem, aes(interests_dem$Law, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward law") + xlab("Law")

h16 <- ggplot(interests_dem, aes(interests_dem$Cars, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("darkorange", "#CC6600")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward cars") + xlab("Cars")

h17 <- ggplot(interests_dem, aes(interests_dem$Art, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF6666", "#66CC99")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward art") + xlab("Art exhibitions")

h18 <- ggplot(interests_dem, aes(interests_dem$Religion, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward religion") + xlab("Religion")

grid.arrange(h10, h11, h12, h13, h14, h15, h16, h17, h18, ncol = 3, nrow =3)
```


&nbsp;


```{r, fig.height=9, fig.width=10, message=FALSE, warning=FALSE}
library(ggplot2); library(gridExtra)

h19 <- ggplot(interests_dem, aes(interests_dem$Outdoor, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.2, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward outdoor") + xlab("Outdoor activities")

h20 <- ggplot(interests_dem, aes(interests_dem$Dancing, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("tan1", "greenyellow")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward dancing") + xlab("Dancing")

h21 <- ggplot(interests_dem, aes(interests_dem$Instruments, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward instruments") + xlab("Playing musical instruments")

h22 <- ggplot(interests_dem, aes(interests_dem$wPoetry, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward wPoetry") + xlab("Poetry writing")

h23 <- ggplot(interests_dem, aes(interests_dem$sLeisure, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.2, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward sLeisure") + xlab("Sport and leisure activities")

h24 <- ggplot(interests_dem, aes(interests_dem$sCompetitive, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.3, 0.85), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward sCompetitive") + xlab("Sport at competitive level")

h25 <- ggplot(interests_dem, aes(interests_dem$Gardening, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#CC79A7", "#0072B2")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward gardening") + xlab("Gardening")

h26 <- ggplot(interests_dem, aes(interests_dem$Celebrities, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("tan1", "greenyellow")) + theme(legend.position=c(0.82, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward Celebrities") + xlab("Celebrity lifestyle")

h27 <- ggplot(interests_dem, aes(interests_dem$Shopping, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF0000", "blue")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward shopping") + xlab("Shopping")

grid.arrange(h19, h20, h21, h22, h23, h24, h25, h26, h27, ncol = 3, nrow =3)
```


&nbsp;

```{r, fig.height=6, fig.width=10, message=FALSE, warning=FALSE}
library(ggplot2); library(gridExtra)


h28 <- ggplot(interests_dem, aes(interests_dem$SciTec, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("darkorange", "#CC6600")) + theme(legend.position=c(0.11, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward SciTec") + xlab("Science and technology")

h29 <- ggplot(interests_dem, aes(interests_dem$Theatre, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("#FF0000", "blue")) + theme(legend.position=c(0.11, 0.85), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward theatre") + xlab("Theatre")

h30 <- ggplot(interests_dem, aes(interests_dem$Social, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.2, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward socializing") + xlab("Socializing with friends")

h31 <- ggplot(interests_dem, aes(interests_dem$sAdrenaline, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("darkorange", "#CC6600")) + theme(legend.position=c(0.9, 0.15), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward sAdrenaline") + xlab("Adrenaline sports")

h32 <- ggplot(interests_dem, aes(interests_dem$Pets, fill = Gender)) + geom_histogram(binwidth = 1, color = "white", alpha = 0.8) + scale_fill_manual(values=c("yellow", "dimgray")) + theme(legend.position=c(0.2, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Interest toward pets") + xlab("Pets")

h33 <- ggplot(interests_dem, aes(interests_dem$Age, fill = Gender)) + geom_histogram(binwidth = 2, color = "white", alpha = 0.8) + scale_fill_manual(values=c("pink", "skyblue")) + theme(legend.position=c(0.8, 0.8), legend.title=element_text(size=8), legend.text = element_text(size = 8)) + ggtitle("Age of participants") + xlab("Age")

grid.arrange(h28, h29, h30, h31, h32, h33, ncol = 3, nrow =2)
```

&nbsp;

# Relationships between different interests and hobbies

&nbsp;

Here my intention is to explore the potential relationships between the different interests and hobbies. First I had to **extract the age and the gender** since they were not a part of my dimension reduction analysis. Then, I had this notable problem with the amount of my variables. First, I printed the correlation matrix including all 32 variable but the table grew so large that it was very difficult to explore it. Also, I figured that the matrix and correlation plot didn't fit well to the web page. Thus, I divided the dataset into the 3 subset to present the correlations at least in some extent. 

**The subsets are divided in a following order**: The first set considers the first 10 variables and the second contains the subsequent 10 variables, i.e. from 11th to 20th. The last subset consists the last 12 variables from 21th to 32th. 

Within the next sub chapters I present the **correlation matrixes**, the tables of their **p-values**, i.e. significance tests and finally I demonstrate both correlations and their significance in **one plot per subset**. I adopted the significance test and its further use with the corrplot from [sthda.com's web examples](http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram). Additionally, 

its worth to mention that the significance level for plotting purposes was set to 0.01 by default and I didn't change it even if it could have also been the "usual" 0.05. Thus the corrplots don't show any color of those associations where the p < 0.01. I thought this in reasonable within this data, especially in terms of relatively low but significant correlations. And the purpose, considering the PCA, is still to find the most important correlations. 


&nbsp;

## First set of correlations

&nbsp;

The first table informs for example that History is related to Politics and Psychology. In my preliminary hypothesis I didn't count the psychology in to the same dimension, thus it is interesting to see what is the final result of Principal Component Analysis. Then you can perceive that Mathematics is quite certainly assiociated to Physics as I thought from the beginning. This relationship can be verified from the p-value table. The same amount of certainty lies between Chemistry and Biology. interestingly, Internet shares a relationship with PC, which I didn't recognize from their histograms. Finally in this table the Economy shares a moderate but significant association with Politics. 



&nbsp;


```{r, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
library(dplyr); library(knitr); library(corrplot)
interests <- dplyr::select(interests_dem, 1:32) # leaving age and gender out

# Dividing the data to groups
interests1 <- dplyr::select(interests, 1:10) # Selecting first set of variables
interests2 <- dplyr::select(interests, 11:20) # Selecting second set of variables
interests3 <- dplyr::select(interests, 21:32) # Selecting rest of the variables

# Presenting the first correlation matrix
cor_matrix1 <- cor(interests1) %>% round(digits = 2)
kable(cor_matrix1, format = "pandoc", digits = 2,  align="c", caption = 'Correlations between the first 10 variables')

# Significance test adopted from: http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram

# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matrix of the p-value of the correlation
p.mat <- cor.mtest(interests1)
kable((p.mat[, 1:10]), format = "pandoc", digits = 3,  align="c", caption = 'p-values, Significance test of correlations')

# Plotting the correlations between first 10 variables along with the significance test
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_matrix1, method = "color", col=col(200),
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```

&nbsp;

## Second set of correlations

&nbsp;

Interestingly, the Reading Poetry has a negative correlation with Cars. Actually I have to admit that I tried to look over only positive relationships from the histograms. Or now I understand that I might have done the exploring in that sense. The Poetry reading has an association also with Foreign Languages and Art Exhibition. The Geography shares only moderate relationships within this subset and its a shame that we can't explore the correlations between the variables considering my initial hypothesis. It is almost the same situation with Medicine, Law, Religion, Outdoor activities and Dancing even though there are significant correlations between these variables. I just think that we can't see the most important ones.    

&nbsp;


```{r, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
library(knitr);library(corrplot)

# Presenting the second correlation matrix
cor_matrix2 <- cor(interests2) %>% round(digits = 2)
kable(cor_matrix2, format = "pandoc", digits = 2,  align="c", caption = 'Correlations between the 11th and 20th variable')


# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matrix of the p-value of the correlation
p.mat <- cor.mtest(interests2)
kable((p.mat[, 1:10]), format = "pandoc", digits = 3,  align="c", caption = 'p-values, Significance test of correlations')

# Plotting the correlations between 11th and 20th variables along with the significance test
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_matrix2, method = "color", col=col(200),
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```


&nbsp;

## Third set of correlations

&nbsp;

Here the Playing instruments has a significant association with Poetry writing. This corresponds with my initial hypothesis. Both variables share a moderate but significant relation with the Gardening as intended. However we will see if the correlation is high enough regarding the PCA. Sport and leisure activities (sLeisure) doesn't show any high correlations even though I imagined that it would share a higher relationship at least with pets, Socializing with friends and Sport at competitive level. 

Interestingly but understandably the celebrity lifestyle is significantly related to shopping. I didn't see this based on thei histograms but its undestandable considering their meaning. Science and technology (SciTec) seems to have moderate but significant relation with the Adrenaline sports. This was something what i doubted in my initial hypothesis. Then the Theatre show a significant association at least with Playing musical instrument.     


&nbsp;


```{r, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
library(knitr); library(corrplot)

# Presenting the third correlation matrix
cor_matrix3 <- cor(interests3) %>% round(digits = 2)
kable(cor_matrix3, format = "pandoc", digits = 2,  align="c", caption = 'Correlations between the rest of the variables')

# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matrix of the p-value of the correlation
p.mat <- cor.mtest(interests3)
kable((p.mat[, 1:12]), format = "pandoc", digits = 3,  align="c", caption = 'p-values, Significance test of correlations')

# Plotting the correlations between the rest of the variables along with the significance test
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_matrix3, method = "color", col=col(200),
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```


&nbsp;

# Principal Component Analysis, PCA

&nbsp;

Principal Component Analysis can be seen as a method of extracting important variables from a large set of variables in a dataset. It extracts low dimensional set of features from a high dimensional dataset with a purpose to capture as much information as possible. [Analytics Vidhya Content Team, Marc 21, 2016](https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/).

The dataset of **Young people's interests** contains multitude dimensions corresponding to 878 observations (n) x 32 variables or predictors (p). We could examine the relationships by means of the scatter plots but there would be as many as **p(p-1)/2** i.e. **496 plots** to explore. This actually makes visible the meaning of PCA, since it allows to deal with high dimensional data.  

A principal component can be seen as a normalized linear combination or the original predictors in a dataset. The first principal component captures the most of the variance in the dataset. The second principal component captures the maximum variance of the dataset that are uncorrelated with the first component. Futhermore, all succeeding principal components follow the similar concept. They capture the remaining variance without being correlated with the previous component. Note that capturing amount of variance corresponds to capturing amount of information. 

&nbsp;

## Scaling the data of interests

&nbsp;

PCA is (always) performed with a numeric and standardized data, which is the reason why I have to scale the data before running the actual analysis.

First I had some problems to use the function "scale()" combined to "ggplot()". I noticed that the scale function converts the data as 'matrix' which is not applicable with ggplot. I didn't find any solution to use "scale" and "ggplot" simultaneously and I definitely didn't want to skip the plotting part. Thus I found another solution from [clusterSim package](https://cran.r-project.org/web/packages/clusterSim/clusterSim.pdf) which allows to standardize the data while it stays as a data frame. The package and its fuction called "data.Normalization" contains multiple transformation possibilities but I chose the formula (n1) corresponding to the "scale" function, i.e. **((x-mean)/sd)**.

Inside the chunk below you can notice that I formatted also the scale function but I don't use it here. I didn't remove it just in case if I need it later. The other purpose is that anyone can verify the similarities of these methods by printing the summaries.

Below you can find the summary of scaled data (data.Normalization) and corresponding histograms. Now the mean of every variable is zero and the observations varies on both sides of zero. This means that the different distributions are now more comparable for the further purposes.


&nbsp;

```{r, fig.height=12, fig.width=12, message=FALSE, warning=FALSE}
library(clusterSim); library(tidyr); library(ggplot2)

# Standardizing the data of interests
std_interests <- scale(interests) # This makes the data as a 'Matrix' and ggplot can't read it

# Scaling/ standardizing the data of interests and printing the summary
norm_interests <- data.Normalization(interests, type = "n1", normalization = "columns")
summary(norm_interests)

# Plotting the data 
gather(norm_interests) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_histogram(color = "white", fill = "orange", binwidth = 1) 
```


&nbsp;

## Performing PCA with Singular Value Decomposition method


&nbsp;

First I will form the analysis but print only the available measures of PCA when using the prcomp() function. The center and the scale refers to respective mean and standard deviation of the variables that are used for normalization prior to implementing PCA. Note that I already standardized my data thus I will not need these functions anymore.

The rotation measure provides the principal component loadings. Each column of rotation matrix contains the principal component loading vector. This is the most important measure we should be interested in. I printed the loadings of each variable considering the initial amount of dimensions regarding my hypotheses. This means a huge amount of measures while the table still can be informative since you can explore where the variables are loading the most and the least. Just for an example I can perceive that matematics and physics are both loading positively to the second component whereas chemistry loads mostly to the third component which is actually against my initial hypothesis. 

The "x" prints the principal component score vector and the "sdev" provides the standard deviavtion of components which I'm not using as such. Instead of this I'm going to print the summary of these measures. Thus let's continue to the next section.  


&nbsp;

```{r, fig.width=8, message=FALSE, warning=FALSE}

# Performing the PCA with Singular Value Decomposition (SVD) method
pca_interests <- prcomp(std_interests)

# Allows us to see the measures of PCA
names(pca_interests)

# A subset of loadings
rotation <- round(pca_interests$rotation[, 1:7], digits = 2)
kable(rotation)
```


&nbsp;

## The summary of PCA with Singular Value Decomposition method

&nbsp;

https://www.analyticsvidhya.com/blog/2016/03/practical-guide-principal-component-analysis-python/

The summary method describe the importance of the PCs. The first row describe again the standard deviation associated with each PC. The second row shows the proportion of the variance in the data explained by each component while the third row describe the cumulative proportion of explained variance.

&nbsp;


```{r, message=FALSE, warning=FALSE}

# Printing a summary of PCA
s <- summary(pca_interests)
s

# rounded percetanges of variance captured by each PCA
pca_pr <- round(100*s$importance[2, ], digits = 1)
print(pca_pr)
```


&nbsp;

The plot method returns a plot of the variances (y-axis) associated with the PCs (x-axis). The Figure below is useful to decide how many PCs to retain for further analysis.


```{r, message=FALSE, warning=FALSE}

# plot method from https://www.r-bloggers.com/computing-and-visualizing-pca-in-r/
plot(pca_interests, type = "l")
```



&nbsp;

```{r, fig.height=10, fig.width=12, message=FALSE, warning=FALSE}

biplot(pca_interests, cex = c(0.8, 1), col = c("dimgrey", "deeppink"), xlab = "something", ylab = "something")
```


&nbsp;



